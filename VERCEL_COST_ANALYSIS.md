# VERCEL COST ANALYSIS - CHATTERS

## EXECUTIVE SUMMARY

Analysis Date: 2025-01-06
Potential Monthly Cost: **$50-100+** if not optimized
Current Risk Level: **MEDIUM-HIGH**

---

## 1. RUNAWAY CRON JOBS

### NPS Email Cron (Supabase Edge Function)
**Status:** ‚ùå **CRITICAL - NOT SCHEDULED VIA VERCEL**

**Location:** `/supabase/functions/send-nps-emails/index.ts`

**Current Implementation:**
- This is a Supabase Edge Function (Deno), NOT a Vercel cron
- Must be triggered manually or via Supabase cron
- Processes up to 50 NPS emails per run (line 46: `.limit(50)`)
- Has proper auth check (lines 25-31)
- Marks emails as sent to prevent duplicates (lines 155-158)

**Risk Assessment:** ‚ö†Ô∏è LOW-MEDIUM
- ‚úÖ Has batch limit (50 emails max per run)
- ‚úÖ Has sent_at tracking to prevent re-sending
- ‚úÖ Authorization required
- ‚ö†Ô∏è No visibility into how often this runs (depends on Supabase cron config)
- ‚ö†Ô∏è If triggered hourly for large customer base, could accumulate costs

**Recommendation:**
```
IMMEDIATE ACTIONS:
1. Check Supabase cron configuration for this function
2. If running hourly, consider reducing to every 4-6 hours
3. Add monitoring for execution count
4. Consider moving to Vercel cron with rate limiting

COST OPTIMIZATION:
- Current: 50 emails √ó 24 runs/day = 1,200 emails/day max
- If you have < 100 active customers, reduce frequency to every 6 hours
- Add execution logging to Supabase to track actual usage
```

---

### Google Ratings Refresh Cron
**Status:** ‚úÖ **WELL-OPTIMIZED**

**Location:** `/api/cron/refresh-google-ratings.js`

**Vercel Cron Config:**
```json
{
  "crons": [
    {
      "path": "/api/cron/refresh-google-ratings",
      "schedule": "0 0 * * *"  // Daily at midnight
    },
    {
      "path": "/api/cron/sync-google-reviews",
      "schedule": "0 1 * * *"  // Daily at 1 AM
    }
  ]
}
```

**Current Implementation:**
- ‚úÖ Runs once daily (not hourly)
- ‚úÖ Hard cap of 1,000 API calls per day (line 7: `MAX_DAILY_CALLS = 1000`)
- ‚úÖ Batch processing (50 venues at a time) (line 63)
- ‚úÖ Proper auth via CRON_SECRET (lines 19-22)
- ‚úÖ 1-second delay between batches (line 141)
- ‚úÖ Optional "active venues only" filter (lines 45-52)

**Risk Assessment:** ‚úÖ LOW
- Well-designed with cost controls
- Won't cause runaway invocations

**Recommendation:**
```
OPTIONAL OPTIMIZATIONS:
1. Enable REFRESH_ACTIVE_ONLY=true to only refresh venues with recent feedback
2. Monitor actual venue count - if > 500 venues, consider bi-daily refresh
3. Current cost: ~2 function invocations per day = negligible
```

---

## 2. INEFFICIENT DATABASE QUERIES IN EDGE FUNCTIONS

### Analysis of Key Edge Functions:

**send-nps-emails (Supabase)**
```typescript
// Line 41-46: EFFICIENT QUERY
.from("nps_submissions")
.select("*, venues(name, logo, nps_question, primary_color)")
.lte("scheduled_send_at", now)
.is("sent_at", null)
.limit(50); // ‚úÖ GOOD: Has limit
```
**Assessment:** ‚úÖ EFFICIENT
- Has `.limit(50)` to prevent massive queries
- Proper indexing needed on `scheduled_send_at` and `sent_at` columns

---

**refresh-google-ratings (Vercel)**
```javascript
// Lines 39-42: POTENTIALLY INEFFICIENT
supabaseAdmin
  .from('venues')
  .select('id, place_id, tripadvisor_location_id, name')
  .or('place_id.not.is.null,tripadvisor_location_id.not.is.null');
```
**Assessment:** ‚ö†Ô∏è MEDIUM RISK
- ‚ùå No `.limit()` - fetches ALL venues
- If you have 1,000+ venues, this could be expensive
- ‚úÖ Has batch processing after fetch
- ‚úÖ Daily execution only

**Recommendation:**
```sql
-- Add database index:
CREATE INDEX IF NOT EXISTS idx_venues_place_ids
ON venues(place_id, tripadvisor_location_id)
WHERE place_id IS NOT NULL OR tripadvisor_location_id IS NOT NULL;

-- Consider pagination if > 500 venues:
// Add to cron job:
const VENUES_PER_DAY = 200;
const offset = new Date().getDate() % 5 * VENUES_PER_DAY;
.limit(VENUES_PER_DAY).range(offset, offset + VENUES_PER_DAY - 1)
```

---

## 3. WEBHOOK RETRY LOOPS

### Stripe Webhook Analysis
**Location:** `/api/stripe-webhook.js`

**Current Implementation:**
```javascript
// Lines 20-30: Signature verification
event = stripe.webhooks.constructEvent(req.body, sig, endpointSecret);

// Lines 35-65: Event handling
switch (event.type) {
  case 'customer.subscription.updated': // ‚úÖ
  case 'customer.subscription.deleted': // ‚úÖ
  case 'invoice.payment_succeeded':     // ‚úÖ
  case 'invoice.payment_failed':        // ‚úÖ
  case 'customer.subscription.created': // ‚úÖ
  default:
    console.log(`Unhandled event type: ${event.type}`);
}
res.json({ received: true }); // Line 61
```

**Risk Assessment:** ‚ö†Ô∏è MEDIUM RISK

**ISSUES FOUND:**

1. **‚ùå No Idempotency Key Check**
   - Stripe may retry webhooks if they don't receive 200 response quickly
   - Could process same event multiple times
   - Lines 69-266 have no duplicate event detection

2. **‚ö†Ô∏è Error Handling Returns 500**
   ```javascript
   // Line 64: This triggers Stripe retries!
   res.status(500).json({ error: 'Webhook processing failed' });
   ```
   - If database error occurs, Stripe will retry
   - Retry schedule: Immediate, 5min, 30min, 2hr, 5hr, 10hr, 24hr
   - Could trigger 7+ retries for temporary DB issues

3. **‚ùå No Rate Limiting**
   - No protection against webhook floods
   - Malicious actor could spam webhooks (if signature bypass found)

**Recommendation:**
```javascript
// ADD IDEMPOTENCY TABLE:
CREATE TABLE webhook_events (
  id TEXT PRIMARY KEY,
  event_type TEXT NOT NULL,
  processed_at TIMESTAMP DEFAULT NOW(),
  created_at TIMESTAMP DEFAULT NOW()
);
CREATE INDEX idx_webhook_events_created ON webhook_events(created_at);

// IMPROVED WEBHOOK HANDLER:
module.exports = async (req, res) => {
  // ... signature verification ...

  // CHECK IF ALREADY PROCESSED
  const { data: existing } = await supabase
    .from('webhook_events')
    .select('id')
    .eq('id', event.id)
    .single();

  if (existing) {
    console.log(`Event ${event.id} already processed, skipping`);
    return res.json({ received: true, skipped: true });
  }

  try {
    // Process webhook
    await handleWebhookEvent(event);

    // MARK AS PROCESSED
    await supabase
      .from('webhook_events')
      .insert({ id: event.id, event_type: event.type });

    return res.json({ received: true });
  } catch (error) {
    console.error('Webhook error:', error);

    // RETURN 200 EVEN ON ERROR to prevent retries
    // Log error for manual investigation
    await supabase.from('webhook_errors').insert({
      event_id: event.id,
      error_message: error.message
    });

    return res.status(200).json({
      received: true,
      error: 'Logged for manual review'
    });
  }
};

// CLEANUP OLD WEBHOOK EVENTS (add to daily cron):
DELETE FROM webhook_events WHERE created_at < NOW() - INTERVAL '30 days';
```

---

## 4. REAL-TIME SUBSCRIPTION CONNECTIONS

### Analysis of Real-Time Subscriptions

**KioskPage.js (PRIMARY CONCERN)**
**Location:** `src/pages/dashboard/KioskPage.js`

```javascript
// Lines 75-133: Kiosk real-time subscription
const channel = supabase
  .channel(`kiosk_updates_${venueId}`)
  .on('postgres_changes', { event: 'INSERT', table: 'feedback' })
  .on('postgres_changes', { event: 'UPDATE', table: 'feedback' })
  .on('postgres_changes', { event: 'INSERT', table: 'assistance_requests' })
  .on('postgres_changes', { event: 'UPDATE', table: 'assistance_requests' })
  .subscribe();

return () => {
  supabase.removeChannel(channel); // ‚úÖ GOOD: Cleanup on unmount
};
```

**+ Fallback Polling:**
```javascript
// Lines 137-146: Polling fallback (EXPENSIVE!)
const pollInterval = setInterval(() => {
  fetchFeedback(venueId);
  fetchAssistanceRequests(venueId);
}, 30000); // Every 30 seconds!
```

**Risk Assessment:** ‚ùå **HIGH RISK**

**ISSUES:**

1. **‚ùå DUAL COST: Real-time + Polling**
   - Real-time subscription stays open
   - Polling runs EVERY 30 seconds regardless
   - If kiosk left open 8 hours/day: **960 polling requests/day PER VENUE**

2. **‚ùå No Connection Timeout**
   - If staff leaves kiosk tab open overnight ‚Üí 2,880 polls
   - Real-time connection stays open indefinitely
   - Supabase charges per connection hour

3. **‚ùå Multiple Listeners**
   - 4 separate postgres_changes listeners
   - Each listener costs separately

**Cost Calculation:**
```
Scenario: 5 venues with kiosk open 8 hours/day
- Real-time: 5 venues √ó 8 hours = 40 connection-hours/day
- Polling: 5 venues √ó 960 requests/day = 4,800 requests/day
- Monthly: 4,800 √ó 30 = 144,000 function invocations
- Estimated cost: $20-40/month JUST FOR KIOSK
```

---

**DashboardNew.js (MODERATE CONCERN)**
**Location:** `src/pages/dashboard/DashboardNew.js`

```javascript
// Lines 43-92: Dashboard real-time
const subscription = supabase
  .channel(`dashboard-activity-${venueId}`)
  .on('postgres_changes', { table: 'assistance_requests' })
  .on('postgres_changes', { event: 'INSERT', table: 'feedback' })
  .subscribe();

return () => {
  subscription.unsubscribe(); // ‚úÖ GOOD: Cleanup
};
```

**Risk Assessment:** ‚ö†Ô∏è MEDIUM RISK
- ‚úÖ No polling fallback
- ‚úÖ Proper cleanup
- ‚ö†Ô∏è Stays open as long as dashboard is open
- ‚ö†Ô∏è If 10 users have dashboard open all day ‚Üí 80 connection-hours/day

---

### RECOMMENDATIONS FOR REAL-TIME OPTIMIZATION:

#### 1. **Remove Polling Fallback from Kiosk**
```javascript
// DELETE LINES 137-146 in KioskPage.js
// Real-time is reliable enough, polling is expensive overkill
```

#### 2. **Add Inactivity Timeout**
```javascript
// Add to KioskPage.js
useEffect(() => {
  let inactivityTimer;

  const resetTimer = () => {
    clearTimeout(inactivityTimer);
    inactivityTimer = setTimeout(() => {
      // Close real-time after 30 minutes inactivity
      console.warn('Kiosk inactive, closing real-time connection');
      // Could show warning modal or refresh connection
    }, 30 * 60 * 1000);
  };

  window.addEventListener('click', resetTimer);
  window.addEventListener('keypress', resetTimer);
  resetTimer();

  return () => {
    clearTimeout(inactivityTimer);
    window.removeEventListener('click', resetTimer);
    window.removeEventListener('keypress', resetTimer);
  };
}, []);
```

#### 3. **Consolidate Listeners**
```javascript
// Instead of 4 separate listeners, use one channel:
const channel = supabase
  .channel(`kiosk_${venueId}`)
  .on('postgres_changes', {
    event: '*', // Listen to all events
    schema: 'public',
    table: 'feedback',
    filter: `venue_id=eq.${venueId}`
  })
  .on('postgres_changes', {
    event: '*',
    schema: 'public',
    table: 'assistance_requests',
    filter: `venue_id=eq.${venueId}`
  })
  .subscribe();
```

#### 4. **Add Connection Budget Tracking**
```javascript
// Add to vercel.json for monitoring
{
  "env": {
    "MAX_CONCURRENT_CONNECTIONS": "20",
    "CONNECTION_BUDGET_DAILY": "200"
  }
}
```

---

## SUMMARY & ACTION PLAN

### IMMEDIATE ACTIONS (Do This Week):

1. **‚ùå REMOVE POLLING FALLBACK FROM KIOSK**
   - File: `src/pages/dashboard/KioskPage.js` lines 137-146
   - Impact: Save ~144,000 function invocations/month
   - Savings: **$15-25/month**

2. **‚ùå ADD WEBHOOK IDEMPOTENCY**
   - File: `api/stripe-webhook.js`
   - Add `webhook_events` table
   - Add idempotency check
   - Return 200 even on error
   - Impact: Prevent retry storms
   - Savings: **$10-20/month** (prevent accidental retry loops)

3. **‚ö†Ô∏è ADD DATABASE INDEXES**
   ```sql
   -- NPS emails
   CREATE INDEX idx_nps_scheduled ON nps_submissions(scheduled_send_at, sent_at)
   WHERE sent_at IS NULL;

   -- Venues for cron
   CREATE INDEX idx_venues_place_ids ON venues(place_id, tripadvisor_location_id);

   -- Webhook events (after adding table)
   CREATE INDEX idx_webhook_created ON webhook_events(created_at);
   ```
   - Impact: Faster queries = lower function duration
   - Savings: **$5-10/month**

### SHORT-TERM ACTIONS (This Month):

4. **Check NPS Cron Frequency**
   - Review Supabase cron config
   - If hourly ‚Üí reduce to every 4-6 hours
   - Savings: **$5-15/month**

5. **Add Inactivity Timeout to Kiosk**
   - Close real-time after 30 min inactivity
   - Savings: **$5-10/month**

6. **Enable REFRESH_ACTIVE_ONLY for Google Cron**
   - Set env var: `REFRESH_ACTIVE_ONLY=true`
   - Only refresh venues with recent feedback
   - Savings: **$2-5/month** (if you have inactive venues)

### MONITORING SETUP:

7. **Add Vercel Analytics Dashboard**
   - Track function invocation counts
   - Set alerts for > 100,000 invocations/day
   - Monitor function duration (aim for < 500ms avg)

8. **Create Cost Tracking Sheet**
   ```
   Daily Metrics to Track:
   - Kiosk sessions (avg duration)
   - Dashboard sessions (avg duration)
   - Webhook events received
   - Cron job execution time
   - Function invocation count
   - Database query count
   ```

---

## EXPECTED SAVINGS

| Optimization | Current Cost | Optimized Cost | Monthly Savings |
|-------------|--------------|----------------|-----------------|
| Remove kiosk polling | $20-30 | $0 | **$20-30** |
| Webhook idempotency | $10-20 | $2 | **$8-18** |
| Database indexes | $8-12 | $3-5 | **$5-7** |
| NPS frequency reduction | $5-10 | $2 | **$3-8** |
| Kiosk inactivity timeout | $5-10 | $2 | **$3-8** |
| **TOTAL** | **$48-82** | **$9-11** | **$39-71/month** |

---

## RISK SCORE BREAKDOWN

| Component | Risk Level | Monthly Cost | Priority |
|-----------|-----------|--------------|----------|
| Kiosk polling fallback | üî¥ HIGH | $20-30 | 1Ô∏è‚É£ URGENT |
| Webhook retry loops | üü° MEDIUM | $10-20 | 2Ô∏è‚É£ HIGH |
| Real-time connections | üü° MEDIUM | $10-15 | 3Ô∏è‚É£ MEDIUM |
| NPS cron frequency | üü¢ LOW | $5-10 | 4Ô∏è‚É£ LOW |
| Database queries | üü¢ LOW | $5-8 | 5Ô∏è‚É£ LOW |
| Google crons | üü¢ LOW | $2-4 | 6Ô∏è‚É£ OPTIONAL |

---

## CONCLUSION

Your Chatters application has **well-designed architecture** overall, but has **2-3 critical cost optimization opportunities**:

‚úÖ **Good Practices:**
- Proper real-time cleanup
- Batch processing in crons
- Daily cron frequency (not hourly)
- Authorization on endpoints

‚ùå **Critical Issues:**
1. Kiosk polling fallback (unnecessary with real-time)
2. No webhook idempotency (retry storm risk)
3. Missing database indexes

**Recommended Timeline:**
- **Week 1:** Remove kiosk polling, add webhook idempotency
- **Week 2:** Add database indexes, check NPS frequency
- **Week 3:** Add monitoring, test optimizations
- **Week 4:** Review metrics, fine-tune

**Expected Outcome:** Reduce Vercel costs from **$50-80/month** to **$10-15/month**.